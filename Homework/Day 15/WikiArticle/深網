深網，即深層網站（英語：Deep web），是指不能被標準搜尋引擎索引的全球資訊網內容。與深網相反的術語是表網，任何人都可以使用網際網路存取。

深網的內容隱藏在HTTP表單後面，包括許多非常常見的用途，如網路郵件、網路銀行、私人或受限制的社群媒體頁面，以及使用者必須付費並受到付費牆保護的服務，如隨選視訊、一些網路雜誌和報紙等。

伯格曼在The Journal of Electronic Publishing上發表一篇關於深網的重大論文中提到，吉爾.艾爾斯沃夫曾經使用「隱形網」這一術語表示那些沒有被任何搜尋引擎索引註冊的網站[1]。伯格曼還參照法蘭克·加西亞在1996年1月的一篇文章[2]：

這些網站可能已經被合理地設計出來了，但是他們卻沒有被任何搜尋引擎編列索引，以至於事實上沒有人能找到他們。我可以這樣對這些不可見的網站說，你們是隱藏了的。我稱之為隱形網。
早期另一個使用「隱形網」這一術語的是一家叫做「個人圖書館軟體」公司的布魯斯·芒特和馬修·B·科爾，當他們公司在1996年12月推出和發行的一款軟體時，他們對深網工具的有過這樣的一番描述。[3]

現在普遍接受的深網這一特定術語首次使用在2001年伯格曼的研究中[1]。2001年，電腦科學家麥可·伯格曼將當今全球資訊網上的搜尋服務比喻為像在地球的海洋表面的拉起一個大網的搜尋，巨量的表面資訊固然可以透過這種方式被尋找得到，可是還有相當大量的資訊由於隱藏在深處而被搜尋引擎錯失掉。絕大部分這些隱藏的資訊是須透過動態請求產生的網頁資訊，而標準的搜尋引擎卻無法對其進行尋找。傳統的搜尋引擎「看」不到，也取得不了這些存在於深網的內容，除非透過特定的搜查這些頁面才會動態產生。於是相對的，深網就隱藏了起來。據估計，深網要比表網大幾個數量級[1]。

防止網頁被傳統搜尋引擎索引的方法可以被分類為以下一個或多個：

研究人員探尋了如何自動抓取深網內容。

2001年，斯利拉姆·拉格哈瓦（Sriram Raghavan）和赫克托·加西亞·莫利納（Hector Garcia-Molina）[6][7]發明了一個從使用者請求介面表格收集關鍵詞的深網抓取模型並且抓取深網資源。加利福尼亞大學洛杉磯分校的Alexandros Ntoulas、Petros Zerfos和Junghoo Cho建立了一個自動生成有意義的查詢詞的程式。[8]

商業搜尋引擎已經開始使用以上兩種方法之一抓取深網。Sitemap協定（由Google於2005年首次開發並由Google引入）和mod oai是允許搜尋引擎和其他網路服務探索深網解決方法。以上兩種解決方法允許網路服務主動公布網址，這對於他們來說是容易的，因而允許自動探尋資源而不直接透過網路表面的連結。Google的深網探尋系統預先計算每個HTML表單並且添加結果HTML頁面到Google搜尋引擎索引。在這個系統里，使用三種方法計算提交詞：

2008年，為了方便Tor隱藏服務的使用者存取和搜尋隱藏的.onion網域，亞倫·斯沃茨設計了Tor2web—一個能夠利用普通瀏覽器存取的代理應用程式[9]。

深網，即深層網站（英語：Deep web），是指不能被標準搜尋引擎索引的全球資訊網內容。與深網相反的術語是表網，任何人都可以使用網際網路存取。

深網的內容隱藏在HTTP表單後面，包括許多非常常見的用途，如網路郵件、網路銀行、私人或受限制的社群媒體頁面，以及使用者必須付費並受到付費牆保護的服務，如隨選視訊、一些網路雜誌和報紙等。

伯格曼在The Journal of Electronic Publishing上發表一篇關於深網的重大論文中提到，吉爾.艾爾斯沃夫曾經使用「隱形網」這一術語表示那些沒有被任何搜尋引擎索引註冊的網站[1]。伯格曼還參照法蘭克·加西亞在1996年1月的一篇文章[2]：

這些網站可能已經被合理地設計出來了，但是他們卻沒有被任何搜尋引擎編列索引，以至於事實上沒有人能找到他們。我可以這樣對這些不可見的網站說，你們是隱藏了的。我稱之為隱形網。
早期另一個使用「隱形網」這一術語的是一家叫做「個人圖書館軟體」公司的布魯斯·芒特和馬修·B·科爾，當他們公司在1996年12月推出和發行的一款軟體時，他們對深網工具的有過這樣的一番描述。[3]

現在普遍接受的深網這一特定術語首次使用在2001年伯格曼的研究中[1]。2001年，電腦科學家麥可·伯格曼將當今全球資訊網上的搜尋服務比喻為像在地球的海洋表面的拉起一個大網的搜尋，巨量的表面資訊固然可以透過這種方式被尋找得到，可是還有相當大量的資訊由於隱藏在深處而被搜尋引擎錯失掉。絕大部分這些隱藏的資訊是須透過動態請求產生的網頁資訊，而標準的搜尋引擎卻無法對其進行尋找。傳統的搜尋引擎「看」不到，也取得不了這些存在於深網的內容，除非透過特定的搜查這些頁面才會動態產生。於是相對的，深網就隱藏了起來。據估計，深網要比表網大幾個數量級[1]。

防止網頁被傳統搜尋引擎索引的方法可以被分類為以下一個或多個：

研究人員探尋了如何自動抓取深網內容。

2001年，斯利拉姆·拉格哈瓦（Sriram Raghavan）和赫克托·加西亞·莫利納（Hector Garcia-Molina）[6][7]發明了一個從使用者請求介面表格收集關鍵詞的深網抓取模型並且抓取深網資源。加利福尼亞大學洛杉磯分校的Alexandros Ntoulas、Petros Zerfos和Junghoo Cho建立了一個自動生成有意義的查詢詞的程式。[8]

商業搜尋引擎已經開始使用以上兩種方法之一抓取深網。Sitemap協定（由Google於2005年首次開發並由Google引入）和mod oai是允許搜尋引擎和其他網路服務探索深網解決方法。以上兩種解決方法允許網路服務主動公布網址，這對於他們來說是容易的，因而允許自動探尋資源而不直接透過網路表面的連結。Google的深網探尋系統預先計算每個HTML表單並且添加結果HTML頁面到Google搜尋引擎索引。在這個系統里，使用三種方法計算提交詞：

2008年，為了方便Tor隱藏服務的使用者存取和搜尋隱藏的.onion網域，亞倫·斯沃茨設計了Tor2web—一個能夠利用普通瀏覽器存取的代理應用程式[9]。

